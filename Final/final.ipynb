{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "201911181 이승민"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 라이브러리 임포트 & spark 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 19:58:18 WARN Utils: Your hostname, Kritiasui-MacBookAir.local resolves to a loopback address: 127.0.0.1; using 172.30.1.23 instead (on interface en0)\n",
      "21/12/18 19:58:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/12/18 19:58:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/18 19:58:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/18 19:58:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "21/12/18 19:58:20 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "myConf = pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession\\\n",
    ".builder\\\n",
    ".master('local')\\\n",
    ".appName('myApp')\\\n",
    ".config(conf=myConf)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-1의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 사용월: string (nullable = true)\n",
      " |-- 호선명: string (nullable = true)\n",
      " |-- 지하철역: string (nullable = true)\n",
      " |-- 유임승차인원: string (nullable = true)\n",
      " |-- 무임승차인원: string (nullable = true)\n",
      " |-- 유임하차인원: string (nullable = true)\n",
      " |-- 무임하차인원: string (nullable = true)\n",
      " |-- 작업일자: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('data', 'myData.csv')\n",
    "myDf = spark.read.option('charset', 'euc-kr')\\\n",
    "    .option('header', 'true')\\\n",
    "    .csv(path)\n",
    "myDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-2의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55171"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-3의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "myDf = myDf.withColumn('i유임승차인원', F.col('유임승차인원').cast(IntegerType()))\n",
    "myDf = myDf.drop('유임승차인원').withColumnRenamed('i유임승차인원', '유임승차인원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+------------+------------+------------+--------+------------+----+\n",
      "|사용월|호선명|지하철역|무임승차인원|유임하차인원|무임하차인원|작업일자|유임승차인원|rank|\n",
      "+------+------+--------+------------+------------+------------+--------+------------+----+\n",
      "|201605|일산선|    화정|      139163|      535460|      142410|20160608|      515925|   1|\n",
      "|201512|일산선|    화정|      136734|      529106|      139931|20160108|      508044|   2|\n",
      "|201603|일산선|    화정|      140596|      526030|      144088|20160408|      502144|   3|\n",
      "|201703|일산선|    화정|      141327|      529944|      145502|20170403|      499911|   4|\n",
      "|201510|일산선|    화정|      520595|      140545|      144148|20151108|      499388|   5|\n",
      "|201905|일산선|    화정|      149790|      520966|      152915|20190603|      499218|   6|\n",
      "|201612|일산선|    화정|      132807|      521734|      136086|20170108|      497514|   7|\n",
      "|201805|일산선|    화정|      139239|      515748|      142997|20180603|      494994|   8|\n",
      "|201610|일산선|    화정|      137462|      513849|      140303|20161108|      492146|   9|\n",
      "|201610|일산선|    화정|      137462|      513849|      140303|20161108|      492146|   9|\n",
      "|201912|일산선|    삼송|      100818|      457339|       99480|20200103|      491895|  11|\n",
      "|201712|일산선|    화정|      127978|      512966|      131552|20180103|      490937|  12|\n",
      "|201910|일산선|    화정|      151951|      508464|      155220|20191103|      490653|  13|\n",
      "|201705|일산선|    화정|      141492|      512873|      145412|20170603|      490644|  14|\n",
      "|201803|일산선|    화정|      137398|      514249|      141440|20180403|      489304|  15|\n",
      "|201803|일산선|    화정|      137398|      514249|      141440|20180403|      489304|  15|\n",
      "|201604|일산선|    화정|      135932|      507461|      139440|20160508|      485899|  17|\n",
      "|201709|일산선|    화정|      139874|      504092|      143148|20171003|      484872|  18|\n",
      "|201910|일산선|    삼송|      105885|      454354|      105185|20191103|      484643|  19|\n",
      "|201810|일산선|    화정|      139895|      509026|      143101|20181103|      484532|  20|\n",
      "|201911|일산선|    화정|      141225|      499920|      143929|20191203|      483740|  21|\n",
      "|201511|일산선|    화정|      505536|      128261|      131672|20151204|      482906|  22|\n",
      "|201611|일산선|    화정|      129876|      508266|      133286|20161208|      482740|  23|\n",
      "|201607|일산선|    화정|      131711|      502448|      134935|20160808|      482155|  24|\n",
      "|201811|일산선|    화정|      132358|      501768|      135435|20181203|      482071|  25|\n",
      "|201704|일산선|    화정|      137811|      502664|      141700|20170503|      480690|  26|\n",
      "|201911|일산선|    삼송|       99525|      450592|       98935|20191203|      480461|  27|\n",
      "|201912|일산선|    화정|      144255|      495808|      147011|20200103|      480423|  28|\n",
      "|201606|일산선|    화정|      134955|      498158|      137884|20160708|      480161|  29|\n",
      "|201711|일산선|    화정|      131931|      500377|      135554|20171203|      476604|  30|\n",
      "+------+------+--------+------------+------------+------------+--------+------------+----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "win = Window.partitionBy('호선명').orderBy(F.col('유임승차인원').desc())\n",
    "myDf = myDf.withColumn('rank', F.rank().over(win))\n",
    "myDf.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-4의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=============================================>          (61 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------------+------------+------------+------------+--------+------------+----+\n",
      "|사용월|        호선명|            지하철역|무임승차인원|유임하차인원|무임하차인원|작업일자|유임승차인원|rank|\n",
      "+------+--------------+--------------------+------------+------------+------------+--------+------------+----+\n",
      "|201605|        일산선|                화정|      139163|      535460|      142410|20160608|      515925|   1|\n",
      "|201905|        장항선|                아산|       12901|       93737|       11808|20190603|      109243|   1|\n",
      "|201512|        경부선|              영등포|      280623|     1545631|      280969|20160108|     1439049|   1|\n",
      "|201905|    우이신설선|        북한산보국문|       45041|      141742|       45814|20190603|      161867|   1|\n",
      "|201512|        분당선|                야탑|      157846|      809197|      156034|20160108|      769442|   1|\n",
      "|201512|         7호선|      가산디지털단지|       82588|     1243464|       78424|20160108|     1245731|   1|\n",
      "|201905|        수인선|              인하대|       28246|      189885|       26442|20190603|      200474|   1|\n",
      "|201603|        안산선|              상록수|       89801|      619361|       90941|20160408|      632180|   1|\n",
      "|201512|         4호선|                혜화|      138010|     1521596|      138133|20160108|     1461258|   1|\n",
      "|201501|         1호선|              서울역|     1667163|      238403|      220008|20150206|     1890411|   1|\n",
      "|201703|        경의선|                일산|       59955|      247634|       60582|20170403|      257203|   1|\n",
      "|201712|         3호선|          고속터미널|      200178|     1760221|      189058|20180103|     1843154|   1|\n",
      "|201910|        경강선|            경기광주|       32028|      186835|       32156|20191103|      201936|   1|\n",
      "|201905|        경춘선|            평내호평|       47748|      155068|       45489|20190603|      155530|   1|\n",
      "|201912|         9호선|              신논현|       65383|     1095786|       62732|20200103|     1063535|   1|\n",
      "|201807|    9호선2단계|              봉은사|       43126|      434135|       40845|20180803|      452395|   1|\n",
      "|201710|         6호선|              이태원|       36941|      680830|       38853|20171103|      580419|   1|\n",
      "|201612|         5호선|광화문(세종문화회관)|      109907|     1404285|      115604|20170108|     1328714|   1|\n",
      "|201907|         8호선|                문정|       57243|      566478|       56677|20190803|      542664|   1|\n",
      "|201907|         8호선|                문정|       57243|      566478|       56677|20190803|      542664|   1|\n",
      "|201907|         8호선|                문정|       57243|      566478|       56677|20190803|      542664|   1|\n",
      "|201512|        과천선|                범계|      111589|      919452|      110456|20160108|      916951|   1|\n",
      "|201603|        경인선|                부천|      212425|     1160226|      212450|20160408|     1173740|   1|\n",
      "|201603|        중앙선|                회기|      135656|      900142|      135321|20160408|      914516|   1|\n",
      "|201912|  9호선2~3단계|              봉은사|       56618|      632524|       53899|20200103|      613139|   1|\n",
      "|201501|         2호선|                강남|     3353256|      164508|      149186|20150206|     3266271|   1|\n",
      "|201708|공항철도 1호선|        인천국제공항|       59577|      508252|       57008|20170903|      545461|   1|\n",
      "|201605|        경원선|              의정부|      130279|      662652|      131349|20160608|      626917|   1|\n",
      "+------+--------------+--------------------+------------+------------+------------+--------+------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "myDf[myDf['rank'] == 1].show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 1-5의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------+------+\n",
      "|    호선명|유임승차인원|meanByLine|sdByLine|zscore|\n",
      "+----------+------------+----------+--------+------+\n",
      "|    경원선|        1580|    1580.0|    null|  null|\n",
      "|    중앙선|        4519|    4519.0|    null|  null|\n",
      "|    경춘선|        4818|    4818.0|    null|  null|\n",
      "|    경강선|        5518|    5518.0|    null|  null|\n",
      "|    중앙선|        6336|    6336.0|    null|  null|\n",
      "|    경춘선|        7554|    7554.0|    null|  null|\n",
      "|    중앙선|       14570|   14570.0|    null|  null|\n",
      "|     4호선|       18498|   18498.0|    null|  null|\n",
      "|    중앙선|       20924|   20924.0|    null|  null|\n",
      "|    경춘선|       22097|   22097.0|    null|  null|\n",
      "|    중앙선|       23015|   23015.0|    null|  null|\n",
      "|    장항선|       23364|   23364.0|    null|  null|\n",
      "|    경춘선|       24347|   24347.0|    null|  null|\n",
      "|    경춘선|       28124|   28124.0|    null|  null|\n",
      "|우이신설선|       28146|   28146.0|    null|  null|\n",
      "|    일산선|       31261|   31261.0|    null|  null|\n",
      "|우이신설선|       32460|   32460.0|    null|  null|\n",
      "|    경강선|       36355|   36355.0|    null|  null|\n",
      "|    경강선|       36538|   36538.0|    null|  null|\n",
      "|우이신설선|       38868|   38868.0|    null|  null|\n",
      "+----------+------------+----------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "allWindow = Window.rowsBetween(-sys.maxsize, sys.maxsize)\n",
    "byLine = Window.partitionBy('유임승차인원')\n",
    "_myDf = myDf.withColumn('meanByLine', F.avg(myDf['유임승차인원']).over(byLine))\n",
    "_myDf = _myDf.withColumn('sdByLine', F.stddev(myDf['유임승차인원']).over(byLine))\n",
    "_myDf = _myDf.withColumn('zscore', (F.col('유임승차인원') - F.col('meanByLine'))/ F.col('sdByLine'))\n",
    "_myDf.select('호선명', '유임승차인원', 'meanByLine', 'sdByLine', 'zscore').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y, coef = make_regression(n_samples = 200, n_features = 4, n_informative = 3, n_targets = 1, noise = 0.0, coef = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradientDescent(x, y, theta, alpha, numIterations):\n",
    "    for i in range(numIterations):\n",
    "        h=np.dot(x, theta)\n",
    "        error=h-y\n",
    "        cost=np.sum((h-y)**2) / len(x)\n",
    "        gradient=np.dot(x.T,error)*2/len(x)\n",
    "        theta-=alpha*gradient\n",
    "        if (i%100==0):\n",
    "            print (\"iter:{0:5d}\\ttheta {1} Cost {2:.5f}\".format(i, theta, cost))\n",
    "    return theta\n",
    "\n",
    "theta = np.ones(X.shape[1])\n",
    "alpha = 0.01\n",
    "iter = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1의 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:    0\ttheta [7.42670134e+01 4.30798370e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  100\ttheta [7.42670134e+01 4.30795534e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  200\ttheta [7.42670134e+01 4.30792699e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  300\ttheta [7.42670134e+01 4.30789864e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  400\ttheta [7.42670134e+01 4.30787028e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  500\ttheta [7.42670134e+01 4.30797671e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  600\ttheta [7.42670134e+01 4.30794835e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  700\ttheta [7.42670134e+01 4.30792000e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  800\ttheta [7.42670134e+01 4.30789165e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "iter:  900\ttheta [7.42670134e+01 4.30786329e-14 5.47295915e+01 6.85430070e+01] Cost 0.00000\n",
      "theta: [7.42670134e+01 4.30792176e-14 5.47295915e+01 6.85430070e+01]\n",
      "coef : [74.26701337  0.         54.72959147 68.54300697]\n"
     ]
    }
   ],
   "source": [
    "result = gradientDescent(X, y, theta, alpha, iter)\n",
    "print('theta: {}\\ncoef : {}'.format(result, coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비교: e표기법과 precision을 고려했을 때, 1.0e-06까지도 완벽히 일치한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2의 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- 0: double (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "#spark.sparkContext.parallelize([X, y][0]).collect()\n",
    "p = spark.sparkContext.parallelize(np.c_[X, y].tolist()).map(lambda x: [x[4], x[0], x[1], x[2], x[3]]).collect()\n",
    "regDf = spark.createDataFrame(p, ['label', '0', '1', '2', '3'])\n",
    "regDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3의 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 77)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = regDf.randomSplit([0.6, 0.4])\n",
    "train.count(), test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4의 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "va = VectorAssembler(inputCols = ['0', '1', '2', '3'], outputCol = 'features')\n",
    "lr = LinearRegression(featuresCol= 'features', labelCol='label', regParam = 0.3)\n",
    "pipe = Pipeline(stages = [va, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipe.fit(train)\n",
    "modelTrainDf = model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계수: [74.09099684760473,-0.017827685057547706,54.57826493514655,68.361389395412]\n",
      "절편: 0.022760266248761388\n"
     ]
    }
   ],
   "source": [
    "print(f'계수: {model.stages[-1].coefficients}\\n절편: {model.stages[-1].intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5의 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|              label|         prediction|\n",
      "+-------------------+-------------------+\n",
      "|-271.82399152124515|-271.12746023757296|\n",
      "|-243.29785695943897|-242.67083779679365|\n",
      "| -203.2411663154771| -202.6832498263636|\n",
      "|-182.80875618802804|-182.32493315948338|\n",
      "| -160.0358893154457|-159.59440156866688|\n",
      "| -151.0358225348507|-150.59257288286264|\n",
      "|-147.63028516080954|-147.23685931325844|\n",
      "|-138.72700790926731|-138.37877711304202|\n",
      "|-120.44878726263362|-120.11430733035846|\n",
      "|-107.73438186080229|-107.39699589924034|\n",
      "+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictDf = model.transform(test)\n",
    "predictDf.select('label', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3번"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 긍부정: string (nullable = true)\n",
      " |-- 리뷰: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myD = []\n",
    "with open(os.path.join('data', 'movie.txt')) as f:\n",
    "    for line in f.readlines():\n",
    "        myD.append((line[0], line[1:].strip()))\n",
    "\n",
    "moDf = spark.createDataFrame(myD, ['긍부정', '리뷰'])\n",
    "moDf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------+--------------------------------+--------------------------------+\n",
      "|긍부정|                              리뷰|                           words|                         nostops|\n",
      "+------+----------------------------------+--------------------------------+--------------------------------+\n",
      "|     0|고구마 먹은 영화 유치해서 못보겠다|  [고구마, 먹은, 영화, 유치해...|  [고구마, 먹은, 영화, 유치해...|\n",
      "|     0|  노잼이네요.. 왜 배우들이 출연...|  [노잼이네요.., 왜, 배우들이...|  [노잼이네요.., 왜, 배우들이...|\n",
      "|     0|   제발 뻘짓 좀 그만하셨으면......|  [제발, 뻘짓, 좀, 그만하셨으...|  [제발, 뻘짓, 좀, 그만하셨으...|\n",
      "|     0|         스토리가 매우 매우 아쉽다|  [스토리가, 매우, 매우, 아쉽다]|  [스토리가, 매우, 매우, 아쉽다]|\n",
      "|     0|             영화 약간 이해가 안됨|      [영화, 약간, 이해가, 안됨]|      [영화, 약간, 이해가, 안됨]|\n",
      "|     0|좋아하는 배우들인데 최근 영화라...| [좋아하는, 배우들인데, 최근,...| [좋아하는, 배우들인데, 최근,...|\n",
      "|     0| 그지같네 도대체 이 따위 영화를...|  [그지같네, 도대체, 이, 따위...|  [그지같네, 도대체, 이, 따위...|\n",
      "|     0|  스크린보다 시계를 더 많이 봄....|  [스크린보다, 시계를, 더, 많...|  [스크린보다, 시계를, 많이, ...|\n",
      "|     0| 이때까지 본 영화중에 제일 최악...|  [이때까지, 본, 영화중에, 제...|  [이때까지, 영화중에, 제일, ...|\n",
      "|     0|    나만 짜증.. 줄거리 한줄평.....|    [나만, 짜증.., 줄거리, 한...|    [나만, 짜증.., 줄거리, 한...|\n",
      "|     0|로맨틱 코미디로 방향을 잡았으면...|  [로맨틱, 코미디로, 방향을, ...|  [로맨틱, 코미디로, 방향을, ...|\n",
      "|     0| 똥 싸다가 막힌 느낌 안보는거를...|    [똥, 싸다가, 막힌, 느낌, ...|    [똥, 싸다가, 막힌, 느낌, ...|\n",
      "|     0|  어우 핵노잼 영화가 왜 이렇게 ...|   [어우, 핵노잼, 영화가, 왜,...|   [어우, 핵노잼, 영화가, 왜,...|\n",
      "|     0| 솔직히 재미없음 감독이 뭘 말할...|  [솔직히, 재미없음, 감독이, ...|  [솔직히, 재미없음, 감독이, ...|\n",
      "|     0|   뭘 말하고싶은지 모르겠다 아쉽다| [뭘, 말하고싶은지, 모르겠다,...| [뭘, 말하고싶은지, 모르겠다,...|\n",
      "|     0| 새벽에 케이블에서 볼거 없어서 ...|  [새벽에, 케이블에서, 볼거, ...|  [새벽에, 케이블에서, 볼거, ...|\n",
      "|     0|         핵노잼 억지 착한척 오졌다|  [핵노잼, 억지, 착한척, 오졌다]|  [핵노잼, 억지, 착한척, 오졌다]|\n",
      "|     0|오그라드는 대사는 기본에 옵션으...| [오그라드는, 대사는, 기본에,...| [오그라드는, 대사는, 기본에,...|\n",
      "|     0| 역대급 호화캐스팅인데 스토리, ...|[역대급, 호화캐스팅인데, 스토...|[역대급, 호화캐스팅인데, 스토...|\n",
      "|     0|  스토리 개 말도 안되는 억지 고...|   [스토리, 개, 말도, 안되는,...|  [스토리, 말도, 안되는, 억지...|\n",
      "+------+----------------------------------+--------------------------------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "tok = Tokenizer(inputCol='리뷰', outputCol= 'words')\n",
    "tokDf = tok.transform(moDf)\n",
    "stop = StopWordsRemover(inputCol = 'words', outputCol= 'nostops')\n",
    "stopList = ['!', '.', 'ㅋㅋㅋ', 'ㅠ', 'ㄹㅇ', '그', '수', '본', '등', '때', '걸', '다', '게', '날', '짱', '거', '중', '더', '넘', '두', '달', '올', '뻔', '단', '개', '듯']\n",
    "stop.setStopWords(stopList)\n",
    "stopDf = stop.transform(tokDf)\n",
    "stopDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashTF = HashingTF(inputCol = 'nostops', outputCol = 'hash')\n",
    "hashDf = hashTF.transform(stopDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|nostops                                                    |hash                                                                                   |\n",
      "+-----------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "|[고구마, 먹은, 영화, 유치해서, 못보겠다]                   |(262144,[114067,145746,202865,232307,243237],[1.0,1.0,1.0,1.0,1.0])                    |\n",
      "|[노잼이네요.., 왜, 배우들이, 출연했는지, 이해가, 잘, 안됨] |(262144,[14123,77545,102360,123815,178388,221856,252373],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[제발, 뻘짓, 좀, 그만하셨으면...., 이건, 여러모로, 낭비다.]|(262144,[30761,45298,104569,160982,165201,196501,249777],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[스토리가, 매우, 매우, 아쉽다]                             |(262144,[8121,118336,181130],[1.0,2.0,1.0])                                            |\n",
      "|[영화, 약간, 이해가, 안됨]                                 |(262144,[35471,102360,145746,221856],[1.0,1.0,1.0,1.0])                                |\n",
      "+-----------------------------------------------------------+---------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol = 'hash', outputCol = 'idf')\n",
    "\n",
    "idfModel = idf.fit(hashDf)\n",
    "idfDf = idfModel.transform(hashDf)\n",
    "idfDf.select('nostops', 'hash').show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "_idfDf = idfDf.withColumn('label', F.col('긍부정').cast(IntegerType()))\n",
    "nb = NaiveBayes(featuresCol = 'hash', labelCol = 'label', modelType = 'multinomial', predictionCol = 'prediction')\n",
    "model = nb.fit(_idfDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 22:47:51 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/18 22:47:51 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "21/12/18 22:47:55 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "idfDf = _idfDf\n",
    "trainDf, testDf = idfDf.randomSplit([0.5, 0.5])\n",
    "model = nb.fit(trainDf)\n",
    "predictions = model.transform(testDf)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol= 'prediction', labelCol = 'label')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6의 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTest = [(-1, '고구가 먹은 느낌 킬링타음으로도 아쉽다'),\n",
    "          (-1, '내돈 아깝 핵노잼 영화가 이렇게 지루해서 못보겠다'),\n",
    "          (-1, '보다가 채널 돌림 재미없다'),\n",
    "          (-1, '최고의 영화'),\n",
    "          (-1, '여운이 긴 명작'),\n",
    "          (-1, '띵작입니다 몰입하고 숨도 못쉬고 봤어요 꼭 보세요')]\n",
    "realTestDf = spark.createDataFrame((myTest), ['긍부정', '리뷰'])\n",
    "realTestDf = tok.transform(realTestDf)\n",
    "realTestDf = stop.transform(realTestDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realTestDf = hashTF.transform(realTestDf)\n",
    "realTestDf = idfModel.transform(realTestDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------+-------------------------------+-------------------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|긍부정|                              리뷰|                          words|                        nostops|                hash|                 idf|       rawPrediction|         probability|prediction|\n",
      "+------+----------------------------------+-------------------------------+-------------------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    -1|고구가 먹은 느낌 킬링타음으로도...| [고구가, 먹은, 느낌, 킬링타...| [고구가, 먹은, 느낌, 킬링타...|(262144,[8121,745...|(262144,[8121,745...|[-60.776859164829...|[0.91828727620625...|       0.0|\n",
      "|    -1| 내돈 아깝 핵노잼 영화가 이렇게...| [내돈, 아깝, 핵노잼, 영화가...| [내돈, 아깝, 핵노잼, 영화가...|(262144,[35595,47...|(262144,[35595,47...|[-83.651936454055...|[0.98899473334772...|       0.0|\n",
      "|    -1|         보다가 채널 돌림 재미없다| [보다가, 채널, 돌림, 재미없다]| [보다가, 채널, 돌림, 재미없다]|(262144,[103639,2...|(262144,[103639,2...|[-48.417382785033...|[0.90902030077780...|       0.0|\n",
      "|    -1|                       최고의 영화|                 [최고의, 영화]|                 [최고의, 영화]|(262144,[17393,14...|(262144,[17393,14...|[-25.542305495807...|[0.09430314357279...|       1.0|\n",
      "|    -1|                    여운이 긴 명작|             [여운이, 긴, 명작]|             [여운이, 긴, 명작]|(262144,[11597,14...|(262144,[11597,14...|[-38.019564911260...|[0.55539739027764...|       0.0|\n",
      "|    -1|띵작입니다 몰입하고 숨도 못쉬고...|[띵작입니다, 몰입하고, 숨도,...|[띵작입니다, 몰입하고, 숨도,...|(262144,[3788,969...|(262144,[3788,969...|[-87.928602573071...|[0.13496055002489...|       1.0|\n",
      "+------+----------------------------------+-------------------------------+-------------------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 22:57:00 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(realTestDf)\n",
    "predictions.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fe295ad4522a8f3a1c00f73e8c1fc4bffda693b9f244974c35f867e6985c135"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
