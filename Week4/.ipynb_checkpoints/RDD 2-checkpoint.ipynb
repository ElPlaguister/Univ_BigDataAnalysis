{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02c38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d728d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/26 19:49:44 WARN Utils: Your hostname, Kritiasui-MacBookAir.local resolves to a loopback address: 127.0.0.1; using 172.30.1.27 instead (on interface en0)\n",
      "21/09/26 19:49:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/09/26 19:49:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "conf = pyspark.SparkConf()\n",
    "spark = pyspark.sql.SparkSession.builder.master('local').appName('myApp').config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8aa959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[1] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "nRdd = spark.sparkContext.parallelize([1,2,3,4])\n",
    "squared = nRdd.map(lambda x: x**2)\n",
    "print(squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba8abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(squared.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df45e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/ds_spark_2cols.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/ds_spark_2cols.csv\n",
    "35, 2\n",
    "40, 27\n",
    "12, 38\n",
    "15, 31\n",
    "21, 1\n",
    "14, 19\n",
    "46, 1\n",
    "10, 34\n",
    "28, 3\n",
    "48, 1\n",
    "16, 2\n",
    "30, 3\n",
    "32, 2\n",
    "48, 1\n",
    "31, 2\n",
    "22, 1\n",
    "12, 3\n",
    "39, 29\n",
    "19, 37\n",
    "25, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8192ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRdd4 = spark.sparkContext\\\n",
    ".textFile(os.path.join('data', 'ds_spark_2cols.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd90d20c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35, 2', '40, 27', '12, 38', '15, 31', '21, 1']\n",
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(myRdd4.take(5))\n",
    "print(type(myRdd4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48064b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['35', ' 2'], ['40', ' 27'], ['12', ' 38'], ['15', ' 31'], ['21', ' 1']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd5 = myRdd4.map(lambda line : line.split(','))\n",
    "myRdd5.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd77b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 2]\n"
     ]
    }
   ],
   "source": [
    "x = ['35', '2']\n",
    "y = list()\n",
    "for i in x:\n",
    "    y.append(int(i))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b40699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 2]\n"
     ]
    }
   ],
   "source": [
    "x = ['35', '2']\n",
    "y = [int(i) for i in x]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430e1f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 2], [40, 27], [12, 38], [15, 31], [21, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRdd6 = myRdd5.map(lambda x: [int(i) for i in x])\n",
    "myRdd6.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfe231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('내가 그린 기린 그림은 잘 그린 기린 그림이고 네가 그린 기린 그림은 잘 못 그린 기린 그림이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ebac201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is'], ['a', 'line']]\n"
     ]
    }
   ],
   "source": [
    "myList = ['this is', 'a line']\n",
    "_rdd = spark.sparkContext.parallelize(myList)\n",
    "\n",
    "wordsRdd = _rdd.map(lambda x: x.split())\n",
    "print(wordsRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "711fca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is', 'AA line']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repRdd = _rdd.map(lambda x: x.replace('a', 'AA'))\n",
    "repRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0df3a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THIS', 'A']\n"
     ]
    }
   ],
   "source": [
    "upperRdd = wordsRdd.map(lambda x: x[0].upper())\n",
    "print(upperRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8946454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['THIS', 'IS'], ['A', 'LINE']]\n"
     ]
    }
   ],
   "source": [
    "upper2RDD = wordsRdd.map(lambda x: [i.upper() for i in x])\n",
    "print(upper2RDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f06cda50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050\n"
     ]
    }
   ],
   "source": [
    "myRdd100 = spark.sparkContext.parallelize(range(1, 101))\n",
    "res = myRdd100.reduce(lambda subtotal, x: subtotal + x)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c7e2d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum:  5050\n",
      "min:  1\n",
      "max:  100\n",
      "standard deviation:  28.86607004772212\n",
      "variance:  833.25\n"
     ]
    }
   ],
   "source": [
    "print(\"sum: \", myRdd100.sum())\n",
    "print(\"min: \", myRdd100.min())\n",
    "print(\"max: \", myRdd100.max())\n",
    "print(\"standard deviation: \", myRdd100.stdev())\n",
    "print(\"variance: \", myRdd100.variance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c163bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world', 'hellow python', 'Hello world']\n"
     ]
    }
   ],
   "source": [
    "myRdd2 = spark.sparkContext.parallelize(['hello world', 'hellow python', 'hellO myFriend', 'Hello world'])\n",
    "myRdd_spark = myRdd2.filter(lambda line: 'llo' in line)\n",
    "print(myRdd_spark.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8364057e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "RDD is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lr/jj1kxjwn315g3cjyb46358l80000gn/T/ipykernel_7041/3484688956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyRdd_unicode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyRdd2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mu'스파크'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyRdd_unicode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RDD is empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: RDD is empty"
     ]
    }
   ],
   "source": [
    "myRdd_unicode = myRdd2.filter(lambda line: u'스파크' in line)\n",
    "print(myRdd_unicode.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06e0bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['is', 'am', 'are', 'the', 'for', 'a', 'an', 'at']\n",
    "myRdd_stop = myRdd2.flatMap(lambda x: x.split())\\\n",
    ".filter(lambda x: x not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfc5c6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world hellow python hellO myFriend Hello world "
     ]
    }
   ],
   "source": [
    "for words in myRdd_stop.collect():\n",
    "    print(words, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8324ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/boj_desc.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/boj_desc.txt\n",
    "John and Ada are sitting on the grass above a small hill. It is midnight and the sky is full of stars. The sky looks like a 2D plane from so far away and the stars look like points on that plane. Ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white. She loves the blue star so much that she wants to trap it. And she asks John for help.\n",
    "\n",
    "Ada will tell John the position of the blue star and he has to trap it. To trap it, John has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter. The vertices of the polygon must be the white stars.\n",
    "\n",
    "Even though John is super awesome, he needs your help. Given the positions of the white stars and the blue star, you need to find out whether John can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2725a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John and Ada are sitting on the grass above a small hill. It is midnight and the sky is full of stars. The sky looks like a 2D plane from so far away and the stars look like points on that plane. Ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white. She loves the blue star so much that she wants to trap it. And she asks John for help.',\n",
       " '',\n",
       " 'Ada will tell John the position of the blue star and he has to trap it. To trap it, John has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter. The vertices of the polygon must be the white stars.',\n",
       " '',\n",
       " 'Even though John is super awesome, he needs your help. Given the positions of the white stars and the blue star, you need to find out whether John can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd = spark.sparkContext.textFile(os.path.join('data', 'boj_desc.txt'))\n",
    "bojRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d858733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John and Ada are sitting on the grass above a small hill. It is midnight and the sky is full of stars. The sky looks like a 2D plane from so far away and the stars look like points on that plane. Ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white. She loves the blue star so much that she wants to trap it. And she asks John for help.',\n",
       " 'Ada will tell John the position of the blue star and he has to trap it. To trap it, John has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter. The vertices of the polygon must be the white stars.',\n",
       " 'Even though John is super awesome, he needs your help. Given the positions of the white stars and the blue star, you need to find out whether John can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd1 = bojRdd.filter(lambda x: x != '')\n",
    "bojRdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4e6423e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john and ada are sitting on the grass above a small hill. it is midnight and the sky is full of stars. the sky looks like a 2d plane from so far away and the stars look like points on that plane. ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white. she loves the blue star so much that she wants to trap it. and she asks john for help.',\n",
       " 'ada will tell john the position of the blue star and he has to trap it. to trap it, john has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter. the vertices of the polygon must be the white stars.',\n",
       " 'even though john is super awesome, he needs your help. given the positions of the white stars and the blue star, you need to find out whether john can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_lower = bojRdd1.map(lambda x: x.lower())\n",
    "bojRdd_lower.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea03cbe",
   "metadata": {},
   "source": [
    "## 문단 합쳐 단어 별로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3968277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john',\n",
       " 'and',\n",
       " 'ada',\n",
       " 'are',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'the',\n",
       " 'grass',\n",
       " 'above',\n",
       " 'a',\n",
       " 'small',\n",
       " 'hill.',\n",
       " 'it',\n",
       " 'is',\n",
       " 'midnight',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'full',\n",
       " 'of',\n",
       " 'stars.',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'a',\n",
       " '2d',\n",
       " 'plane',\n",
       " 'from',\n",
       " 'so',\n",
       " 'far',\n",
       " 'away',\n",
       " 'and',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'look',\n",
       " 'like',\n",
       " 'points',\n",
       " 'on',\n",
       " 'that',\n",
       " 'plane.',\n",
       " 'ada',\n",
       " 'loves',\n",
       " 'blue',\n",
       " 'stars',\n",
       " 'and',\n",
       " 'suddenly',\n",
       " 'she',\n",
       " 'notices',\n",
       " 'one,',\n",
       " 'while',\n",
       " 'all',\n",
       " 'the',\n",
       " 'other',\n",
       " 'stars',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'are',\n",
       " 'white.',\n",
       " 'she',\n",
       " 'loves',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it.',\n",
       " 'and',\n",
       " 'she',\n",
       " 'asks',\n",
       " 'john',\n",
       " 'for',\n",
       " 'help.',\n",
       " 'ada',\n",
       " 'will',\n",
       " 'tell',\n",
       " 'john',\n",
       " 'the',\n",
       " 'position',\n",
       " 'of',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'and',\n",
       " 'he',\n",
       " 'has',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it.',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it,',\n",
       " 'john',\n",
       " 'has',\n",
       " 'to',\n",
       " 'draw',\n",
       " 'a',\n",
       " 'polygon',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'with',\n",
       " 'his',\n",
       " 'buster',\n",
       " 'sword,',\n",
       " 'so',\n",
       " 'that',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'is',\n",
       " 'strictly',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'polygon',\n",
       " '(not',\n",
       " 'on',\n",
       " 'the',\n",
       " 'border',\n",
       " 'of',\n",
       " 'the',\n",
       " 'polygon)',\n",
       " 'and',\n",
       " 'the',\n",
       " 'polygon',\n",
       " 'has',\n",
       " 'the',\n",
       " 'smallest',\n",
       " 'possible',\n",
       " 'perimeter.',\n",
       " 'the',\n",
       " 'vertices',\n",
       " 'of',\n",
       " 'the',\n",
       " 'polygon',\n",
       " 'must',\n",
       " 'be',\n",
       " 'the',\n",
       " 'white',\n",
       " 'stars.',\n",
       " 'even',\n",
       " 'though',\n",
       " 'john',\n",
       " 'is',\n",
       " 'super',\n",
       " 'awesome,',\n",
       " 'he',\n",
       " 'needs',\n",
       " 'your',\n",
       " 'help.',\n",
       " 'given',\n",
       " 'the',\n",
       " 'positions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'white',\n",
       " 'stars',\n",
       " 'and',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'star,',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'whether',\n",
       " 'john',\n",
       " 'can',\n",
       " 'trap',\n",
       " 'the',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'and',\n",
       " 'if',\n",
       " 'he',\n",
       " 'can,',\n",
       " 'also',\n",
       " 'find',\n",
       " 'the',\n",
       " 'minimum',\n",
       " 'length',\n",
       " 'of',\n",
       " 'the',\n",
       " 'perimeter',\n",
       " 'of',\n",
       " 'the',\n",
       " 'polygon',\n",
       " 'he',\n",
       " 'will',\n",
       " 'use.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_flatSplit = bojRdd_lower.flatMap(lambda x: x.split())\n",
    "bojRdd_flatSplit.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b292c8b",
   "metadata": {},
   "source": [
    "## Stopword 걸러내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9f5854b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john',\n",
       " 'and',\n",
       " 'ada',\n",
       " 'sitting',\n",
       " 'on',\n",
       " 'grass',\n",
       " 'above',\n",
       " 'small',\n",
       " 'hill.',\n",
       " 'it',\n",
       " 'midnight',\n",
       " 'and',\n",
       " 'sky',\n",
       " 'full',\n",
       " 'of',\n",
       " 'stars.',\n",
       " 'sky',\n",
       " 'looks',\n",
       " 'like',\n",
       " '2d',\n",
       " 'plane',\n",
       " 'from',\n",
       " 'so',\n",
       " 'far',\n",
       " 'away',\n",
       " 'and',\n",
       " 'stars',\n",
       " 'look',\n",
       " 'like',\n",
       " 'points',\n",
       " 'on',\n",
       " 'that',\n",
       " 'plane.',\n",
       " 'ada',\n",
       " 'loves',\n",
       " 'blue',\n",
       " 'stars',\n",
       " 'and',\n",
       " 'suddenly',\n",
       " 'she',\n",
       " 'notices',\n",
       " 'one,',\n",
       " 'while',\n",
       " 'all',\n",
       " 'other',\n",
       " 'stars',\n",
       " 'in',\n",
       " 'sky',\n",
       " 'white.',\n",
       " 'she',\n",
       " 'loves',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'she',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it.',\n",
       " 'and',\n",
       " 'she',\n",
       " 'asks',\n",
       " 'john',\n",
       " 'help.',\n",
       " 'ada',\n",
       " 'will',\n",
       " 'tell',\n",
       " 'john',\n",
       " 'position',\n",
       " 'of',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'and',\n",
       " 'he',\n",
       " 'has',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it.',\n",
       " 'to',\n",
       " 'trap',\n",
       " 'it,',\n",
       " 'john',\n",
       " 'has',\n",
       " 'to',\n",
       " 'draw',\n",
       " 'polygon',\n",
       " 'in',\n",
       " 'sky',\n",
       " 'with',\n",
       " 'his',\n",
       " 'buster',\n",
       " 'sword,',\n",
       " 'so',\n",
       " 'that',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'strictly',\n",
       " 'inside',\n",
       " 'polygon',\n",
       " '(not',\n",
       " 'on',\n",
       " 'border',\n",
       " 'of',\n",
       " 'polygon)',\n",
       " 'and',\n",
       " 'polygon',\n",
       " 'has',\n",
       " 'smallest',\n",
       " 'possible',\n",
       " 'perimeter.',\n",
       " 'vertices',\n",
       " 'of',\n",
       " 'polygon',\n",
       " 'must',\n",
       " 'be',\n",
       " 'white',\n",
       " 'stars.',\n",
       " 'even',\n",
       " 'though',\n",
       " 'john',\n",
       " 'super',\n",
       " 'awesome,',\n",
       " 'he',\n",
       " 'needs',\n",
       " 'your',\n",
       " 'help.',\n",
       " 'given',\n",
       " 'positions',\n",
       " 'of',\n",
       " 'white',\n",
       " 'stars',\n",
       " 'and',\n",
       " 'blue',\n",
       " 'star,',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'whether',\n",
       " 'john',\n",
       " 'can',\n",
       " 'trap',\n",
       " 'blue',\n",
       " 'star',\n",
       " 'and',\n",
       " 'if',\n",
       " 'he',\n",
       " 'can,',\n",
       " 'also',\n",
       " 'find',\n",
       " 'minimum',\n",
       " 'length',\n",
       " 'of',\n",
       " 'perimeter',\n",
       " 'of',\n",
       " 'polygon',\n",
       " 'he',\n",
       " 'will',\n",
       " 'use.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = ['is', 'am', 'are', 'the', 'for', 'a', 'an', 'at']\n",
    "bojRdd_filtered = bojRdd_flatSplit.filter(lambda x : x not in stopwords)\n",
    "bojRdd_filtered.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234cb4f",
   "metadata": {},
   "source": [
    "## '.' 기준으로 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8031ef1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john and ada sitting on grass above small hill. it midnight and sky full of stars. sky looks like 2d plane from so far away and stars look like points on that plane. ada loves blue stars and suddenly she notices one, while all other stars in sky white. she loves blue star so much that she wants to trap it. and she asks john help. ada will tell john position of blue star and he has to trap it. to trap it, john has to draw polygon in sky with his buster sword, so that blue star strictly inside polygon (not on border of polygon) and polygon has smallest possible perimeter. vertices of polygon must be white stars. even though john super awesome, he needs your help. given positions of white stars and blue star, you need to find out whether john can trap blue star and if he can, also find minimum length of perimeter of polygon he will use.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_reduce = spark.sparkContext.parallelize([bojRdd_filtered.reduce(lambda first, second: first + ' ' + second)])\n",
    "bojRdd_reduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f8fc688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john and ada sitting on grass above small hill',\n",
       " 'it midnight and sky full of stars',\n",
       " 'sky looks like 2d plane from so far away and stars look like points on that plane',\n",
       " 'ada loves blue stars and suddenly she notices one, while all other stars in sky white',\n",
       " 'she loves blue star so much that she wants to trap it',\n",
       " 'and she asks john help',\n",
       " 'ada will tell john position of blue star and he has to trap it',\n",
       " 'to trap it, john has to draw polygon in sky with his buster sword, so that blue star strictly inside polygon (not on border of polygon) and polygon has smallest possible perimeter',\n",
       " 'vertices of polygon must be white stars',\n",
       " 'even though john super awesome, he needs your help',\n",
       " 'given positions of white stars and blue star, you need to find out whether john can trap blue star and if he can, also find minimum length of perimeter of polygon he will use.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_split = bojRdd_reduce.map(lambda x: x.split('. '))\n",
    "bojRdd_split.collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f4355",
   "metadata": {},
   "source": [
    "# 파이프라인 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "905cc08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['john and ada sitting on grass above small hill', 'it midnight and sky full of stars', 'sky looks like 2d plane from so far away and stars look like points on that plane', 'ada loves blue stars and suddenly she notices one, while all other stars in sky white', 'she loves blue star so much that she wants to trap it', 'and she asks john help', 'ada will tell john position of blue star and he has to trap it', 'to trap it, john has to draw polygon in sky with his buster sword, so that blue star strictly inside polygon (not on border of polygon) and polygon has smallest possible perimeter', 'vertices of polygon must be white stars', 'even though john super awesome, he needs your help', 'given positions of white stars and blue star, you need to find out whether john can trap blue star and if he can, also find minimum length of perimeter of polygon he will use.']]\n"
     ]
    }
   ],
   "source": [
    "bojRdd_res = spark.sparkContext.parallelize([bojRdd.filter(lambda x: x !='')\\\n",
    ".map(lambda x: x.lower())\\\n",
    ".flatMap(lambda x: x.split())\\\n",
    ".filter(lambda x: x not in stopwords)\\\n",
    ".reduce(lambda first, second: first + ' ' + second)])\\\n",
    ".map(lambda x: x.split('. '))\n",
    "print(bojRdd_res.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26b5b4",
   "metadata": {},
   "source": [
    "# 파일에 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99a2dc2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lr/jj1kxjwn315g3cjyb46358l80000gn/T/ipykernel_7041/4237608074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbojRdd_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveAsTextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ds_boj_out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(self, c, numSlices)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# Make sure we distribute data evenly if it's smaller than self.batchSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"__len__\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Make it a list so we can compute its length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mbatchSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnumSlices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchSize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbatched_serializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object is not iterable"
     ]
    }
   ],
   "source": [
    "spark.sparkContext.parallelize(bojRdd_res).saveAsTextFile(os.path.join('data', 'ds_boj_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "34f42949",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.parallelize(bojRdd_split.collect()).saveAsTextFile(os.path.join('data', 'ds_boj_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b25d5df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rw-r--r--  1 elplaguister  staff    0  9 27 00:32 _SUCCESS\r\n",
      "-rw-r--r--  1 elplaguister  staff  870  9 27 00:32 part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/ds_boj_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f7b00e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['john and ada sitting on grass above small hill', 'it midnight and sky full of stars', 'sky looks like 2d plane from so far away and stars look like points on that plane', 'ada loves blue stars and suddenly she notices one, while all other stars in sky white', 'she loves blue star so much that she wants to trap it', 'and she asks john help', 'ada will tell john position of blue star and he has to trap it', 'to trap it, john has to draw polygon in sky with his buster sword, so that blue star strictly inside polygon (not on border of polygon) and polygon has smallest possible perimeter', 'vertices of polygon must be white stars', 'even though john super awesome, he needs your help', 'given positions of white stars and blue star, you need to find out whether john can trap blue star and if he can, also find minimum length of perimeter of polygon he will use.']\"]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.textFile(os.path.join('data', 'ds_boj_out')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f719765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bojRdd_split.map(lambda x: ''.join(x)).coalesce(1).saveAsTextFile(os.path.join('data', 'ds_boj_txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a84b3e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john and ada sitting on grass above small hillit midnight and sky full of starssky looks like 2d plane from so far away and stars look like points on that planeada loves blue stars and suddenly she notices one, while all other stars in sky whiteshe loves blue star so much that she wants to trap itand she asks john helpada will tell john position of blue star and he has to trap itto trap it, john has to draw polygon in sky with his buster sword, so that blue star strictly inside polygon (not on border of polygon) and polygon has smallest possible perimetervertices of polygon must be white starseven though john super awesome, he needs your helpgiven positions of white stars and blue star, you need to find out whether john can trap blue star and if he can, also find minimum length of perimeter of polygon he will use.\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/ds_boj_txt/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f763587",
   "metadata": {},
   "source": [
    "# groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86e08767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John and Ada are sitting on the grass above a small hill.',\n",
       " 'It is midnight and the sky is full of stars.',\n",
       " 'The sky looks like a 2D plane from so far away and the stars look like points on that plane.',\n",
       " 'Ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white.',\n",
       " 'She loves the blue star so much that she wants to trap it.',\n",
       " 'And she asks John for help.',\n",
       " 'Ada will tell John the position of the blue star and he has to trap it.',\n",
       " 'To trap it, John has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter.',\n",
       " 'The vertices of the polygon must be the white stars.',\n",
       " 'Even though John is super awesome, he needs your help.',\n",
       " 'Given the positions of the white stars and the blue star, you need to find out whether John can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use.']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_base = bojRdd.map(lambda article: article.replace('.', '.|'))\\\n",
    ".flatMap(lambda article: article.split('|'))\\\n",
    ".filter(lambda line: line != '')\\\n",
    ".map(lambda line: line.strip())\n",
    "bojRdd_base.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "92c755d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jo', <pyspark.resultiterable.ResultIterable object at 0x7fad4e1197c0>), ('It', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d760>), ('Th', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d1f0>), ('Ad', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d910>), ('Sh', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d610>), ('An', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d580>), ('To', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13db80>), ('Ev', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d6d0>), ('Gi', <pyspark.resultiterable.ResultIterable object at 0x7fad4e13d670>)]\n",
      "Jo: John and Ada are sitting on the grass above a small hill.\n",
      "-----\n",
      "It: It is midnight and the sky is full of stars.\n",
      "-----\n",
      "Th: The sky looks like a 2D plane from so far away and the stars look like points on that plane.\n",
      "Th: The vertices of the polygon must be the white stars.\n",
      "-----\n",
      "Ad: Ada loves blue stars and suddenly she notices one, while all the other stars in the sky are white.\n",
      "Ad: Ada will tell John the position of the blue star and he has to trap it.\n",
      "-----\n",
      "Sh: She loves the blue star so much that she wants to trap it.\n",
      "-----\n",
      "An: And she asks John for help.\n",
      "-----\n",
      "To: To trap it, John has to draw a polygon in the sky with his buster sword, so that the blue star is strictly inside the polygon (not on the border of the polygon) and the polygon has the smallest possible perimeter.\n",
      "-----\n",
      "Ev: Even though John is super awesome, he needs your help.\n",
      "-----\n",
      "Gi: Given the positions of the white stars and the blue star, you need to find out whether John can trap the blue star and if he can, also find the minimum length of the perimeter of the polygon he will use.\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "bojRdd_first2Group = bojRdd_base.groupBy(lambda x: x[0:2])\n",
    "print(bojRdd_first2Group.collect())\n",
    "\n",
    "for (k, v) in bojRdd_first2Group.collect():\n",
    "    for eachValue in v:\n",
    "        print('{}: {}'.format(k, eachValue))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6bcd55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_testList = [('Seoul', 1),('Seoul', 1),('Seoul', 1),('Busan', 1),('Busan', 1),\n",
    "            ('Seoul', 1),('Busan', 1),\n",
    "            ('Seoul', 1),('Seoul', 1),('Busan', 1),('Busan', 1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7961ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "_testRdd = spark.sparkContext.parallelize(_testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "475b9a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Seoul', <pyspark.resultiterable.ResultIterable at 0x7fad4e13dee0>),\n",
       " ('Busan', <pyspark.resultiterable.ResultIterable at 0x7fad4dbec4c0>)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result Iterable\n",
    "_testRdd.groupBy(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9a0131a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Seoul',\n",
       "  [('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1)]),\n",
       " ('Busan',\n",
       "  [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map Values\n",
    "_testRdd.groupBy(lambda x: x[0]).mapValues(lambda x: list(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4d3adc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Seoul',\n",
       "  [('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1),\n",
       "   ('Seoul', 1)]),\n",
       " ('Busan',\n",
       "  [('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1), ('Busan', 1)])]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.groupBy(lambda x: x[0]).mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb510a",
   "metadata": {},
   "source": [
    "# Pair RDD\n",
    "## key, value\n",
    "### byKey(), byValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f4cb4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "_testList = [('Seoul', 1),('Seoul', 1),('Seoul', 1),('Busan', 1),('Busan', 1),\n",
    "            ('Seoul', 1),('Busan', 1),\n",
    "            ('Seoul', 1),('Seoul', 1),('Busan', 1),('Busan', 1),]\n",
    "_testRdd = spark.sparkContext.parallelize(_testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0ebe0e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partition\n",
    "_testRdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b2c95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, jsl 2020.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2020\n",
    "name = 'jsl'\n",
    "f\"Hello, {name} {year}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "102eae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions 0 -> [('Seoul', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1), ('Seoul', 1), ('Busan', 1), ('Seoul', 1), ('Seoul', 1), ('Busan', 1), ('Busan', 1)]\n"
     ]
    }
   ],
   "source": [
    "partitions = _testRdd.glom().collect()\n",
    "for num, partition in enumerate(partitions):\n",
    "    print(f'Partitions {num} -> {partition}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "df6c275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seoul',\n",
       " 'Seoul',\n",
       " 'Seoul',\n",
       " 'Busan',\n",
       " 'Busan',\n",
       " 'Seoul',\n",
       " 'Busan',\n",
       " 'Seoul',\n",
       " 'Seoul',\n",
       " 'Busan',\n",
       " 'Busan']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3cbd4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Seoul', 6), ('Busan', 5)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_testRdd.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "216eee1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Seoul', [1, 1, 1, 1, 1, 1]), ('Busan', [1, 1, 1, 1, 1])]\n",
      "[('Seoul', 2), ('Seoul', 2), ('Seoul', 2), ('Busan', 2), ('Busan', 2), ('Seoul', 2), ('Busan', 2), ('Seoul', 2), ('Seoul', 2), ('Busan', 2), ('Busan', 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    }
   ],
   "source": [
    "print(_testRdd.groupByKey().mapValues(list).collect())\n",
    "print(_testRdd.mapValues(lambda x: x + 1).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "42759223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', <pyspark.resultiterable.ResultIterable at 0x7fad4d215220>),\n",
       " ('and', <pyspark.resultiterable.ResultIterable at 0x7fad4b8233a0>),\n",
       " ('Ada', <pyspark.resultiterable.ResultIterable at 0x7fad4b823400>)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_base\\\n",
    ".flatMap(lambda x: x.split())\\\n",
    ".map(lambda x: (x, 1))\\\n",
    ".groupByKey()\\\n",
    ".take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ebb9e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    }
   ],
   "source": [
    "bojList = bojRdd_base\\\n",
    ".flatMap(lambda x: x.split())\\\n",
    ".map(lambda x: (x, 1))\\\n",
    ".groupByKey()\\\n",
    ".mapValues(sum)\\\n",
    ".sortByKey(True)\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7ccf3695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어:(not\t\t빈도:1\n",
      "단어:2D\t\t빈도:1\n",
      "단어:Ada\t\t빈도:3\n",
      "단어:And\t\t빈도:1\n",
      "단어:Even\t\t빈도:1\n",
      "단어:Given\t\t빈도:1\n",
      "단어:It\t\t빈도:1\n",
      "단어:John\t\t빈도:6\n",
      "단어:She\t\t빈도:1\n",
      "단어:The\t\t빈도:2\n",
      "단어:To\t\t빈도:1\n",
      "단어:a\t\t빈도:3\n",
      "단어:above\t\t빈도:1\n",
      "단어:all\t\t빈도:1\n",
      "단어:also\t\t빈도:1\n",
      "단어:and\t\t빈도:8\n",
      "단어:are\t\t빈도:2\n",
      "단어:asks\t\t빈도:1\n",
      "단어:away\t\t빈도:1\n",
      "단어:awesome,\t\t빈도:1\n",
      "단어:be\t\t빈도:1\n",
      "단어:blue\t\t빈도:6\n",
      "단어:border\t\t빈도:1\n",
      "단어:buster\t\t빈도:1\n",
      "단어:can\t\t빈도:1\n",
      "단어:can,\t\t빈도:1\n",
      "단어:draw\t\t빈도:1\n",
      "단어:far\t\t빈도:1\n",
      "단어:find\t\t빈도:2\n",
      "단어:for\t\t빈도:1\n",
      "단어:from\t\t빈도:1\n",
      "단어:full\t\t빈도:1\n",
      "단어:grass\t\t빈도:1\n",
      "단어:has\t\t빈도:3\n",
      "단어:he\t\t빈도:4\n",
      "단어:help.\t\t빈도:2\n",
      "단어:hill.\t\t빈도:1\n",
      "단어:his\t\t빈도:1\n",
      "단어:if\t\t빈도:1\n",
      "단어:in\t\t빈도:2\n",
      "단어:inside\t\t빈도:1\n",
      "단어:is\t\t빈도:4\n",
      "단어:it,\t\t빈도:1\n",
      "단어:it.\t\t빈도:2\n",
      "단어:length\t\t빈도:1\n",
      "단어:like\t\t빈도:2\n",
      "단어:look\t\t빈도:1\n",
      "단어:looks\t\t빈도:1\n",
      "단어:loves\t\t빈도:2\n",
      "단어:midnight\t\t빈도:1\n",
      "단어:minimum\t\t빈도:1\n",
      "단어:much\t\t빈도:1\n",
      "단어:must\t\t빈도:1\n",
      "단어:need\t\t빈도:1\n",
      "단어:needs\t\t빈도:1\n",
      "단어:notices\t\t빈도:1\n",
      "단어:of\t\t빈도:7\n",
      "단어:on\t\t빈도:3\n",
      "단어:one,\t\t빈도:1\n",
      "단어:other\t\t빈도:1\n",
      "단어:out\t\t빈도:1\n",
      "단어:perimeter\t\t빈도:1\n",
      "단어:perimeter.\t\t빈도:1\n",
      "단어:plane\t\t빈도:1\n",
      "단어:plane.\t\t빈도:1\n",
      "단어:points\t\t빈도:1\n",
      "단어:polygon\t\t빈도:5\n",
      "단어:polygon)\t\t빈도:1\n",
      "단어:position\t\t빈도:1\n",
      "단어:positions\t\t빈도:1\n",
      "단어:possible\t\t빈도:1\n",
      "단어:she\t\t빈도:3\n",
      "단어:sitting\t\t빈도:1\n",
      "단어:sky\t\t빈도:4\n",
      "단어:small\t\t빈도:1\n",
      "단어:smallest\t\t빈도:1\n",
      "단어:so\t\t빈도:3\n",
      "단어:star\t\t빈도:4\n",
      "단어:star,\t\t빈도:1\n",
      "단어:stars\t\t빈도:4\n",
      "단어:stars.\t\t빈도:2\n",
      "단어:strictly\t\t빈도:1\n",
      "단어:suddenly\t\t빈도:1\n",
      "단어:super\t\t빈도:1\n",
      "단어:sword,\t\t빈도:1\n",
      "단어:tell\t\t빈도:1\n",
      "단어:that\t\t빈도:3\n",
      "단어:the\t\t빈도:24\n",
      "단어:though\t\t빈도:1\n",
      "단어:to\t\t빈도:4\n",
      "단어:trap\t\t빈도:4\n",
      "단어:use.\t\t빈도:1\n",
      "단어:vertices\t\t빈도:1\n",
      "단어:wants\t\t빈도:1\n",
      "단어:whether\t\t빈도:1\n",
      "단어:while\t\t빈도:1\n",
      "단어:white\t\t빈도:2\n",
      "단어:white.\t\t빈도:1\n",
      "단어:will\t\t빈도:2\n",
      "단어:with\t\t빈도:1\n",
      "단어:you\t\t빈도:1\n",
      "단어:your\t\t빈도:1\n"
     ]
    }
   ],
   "source": [
    "for element in bojList:\n",
    "    _key = element[0]\n",
    "    _value = element[1]\n",
    "    print(f'단어:{_key}\\t\\t빈도:{_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6b53342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어:the\t\t빈도:24\n",
      "단어:and\t\t빈도:8\n",
      "단어:of\t\t빈도:7\n",
      "단어:John\t\t빈도:6\n",
      "단어:blue\t\t빈도:6\n",
      "단어:polygon\t\t빈도:5\n",
      "단어:he\t\t빈도:4\n",
      "단어:is\t\t빈도:4\n",
      "단어:sky\t\t빈도:4\n",
      "단어:star\t\t빈도:4\n",
      "단어:stars\t\t빈도:4\n",
      "단어:to\t\t빈도:4\n",
      "단어:trap\t\t빈도:4\n",
      "단어:Ada\t\t빈도:3\n",
      "단어:a\t\t빈도:3\n",
      "단어:has\t\t빈도:3\n",
      "단어:on\t\t빈도:3\n",
      "단어:she\t\t빈도:3\n",
      "단어:so\t\t빈도:3\n",
      "단어:that\t\t빈도:3\n"
     ]
    }
   ],
   "source": [
    "bojSorted = sorted(bojList, key = lambda x: -x[1])[:20]\n",
    "for element in bojSorted:\n",
    "    _key = element[0]\n",
    "    _value = element[1]\n",
    "    print(f'단어:{_key}\\t\\t빈도:{_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5fc33bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elplaguister/opt/anaconda3/envs/Analysis/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('John', 6),\n",
       " ('and', 8),\n",
       " ('Ada', 3),\n",
       " ('are', 2),\n",
       " ('sitting', 1),\n",
       " ('on', 3),\n",
       " ('the', 24),\n",
       " ('grass', 1),\n",
       " ('above', 1),\n",
       " ('a', 3)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_base\\\n",
    ".flatMap(lambda x: x.split())\\\n",
    ".map(lambda x:(x, 1))\\\n",
    ".reduceByKey(lambda x, y: x + y)\\\n",
    ".take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0bd9c22d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'John': 6,\n",
       "             'and': 8,\n",
       "             'Ada': 3,\n",
       "             'are': 2,\n",
       "             'sitting': 1,\n",
       "             'on': 3,\n",
       "             'the': 24,\n",
       "             'grass': 1,\n",
       "             'above': 1,\n",
       "             'a': 3,\n",
       "             'small': 1,\n",
       "             'hill.': 1,\n",
       "             'It': 1,\n",
       "             'is': 4,\n",
       "             'midnight': 1,\n",
       "             'sky': 4,\n",
       "             'full': 1,\n",
       "             'of': 7,\n",
       "             'stars.': 2,\n",
       "             'The': 2,\n",
       "             'looks': 1,\n",
       "             'like': 2,\n",
       "             '2D': 1,\n",
       "             'plane': 1,\n",
       "             'from': 1,\n",
       "             'so': 3,\n",
       "             'far': 1,\n",
       "             'away': 1,\n",
       "             'stars': 4,\n",
       "             'look': 1,\n",
       "             'points': 1,\n",
       "             'that': 3,\n",
       "             'plane.': 1,\n",
       "             'loves': 2,\n",
       "             'blue': 6,\n",
       "             'suddenly': 1,\n",
       "             'she': 3,\n",
       "             'notices': 1,\n",
       "             'one,': 1,\n",
       "             'while': 1,\n",
       "             'all': 1,\n",
       "             'other': 1,\n",
       "             'in': 2,\n",
       "             'white.': 1,\n",
       "             'She': 1,\n",
       "             'star': 4,\n",
       "             'much': 1,\n",
       "             'wants': 1,\n",
       "             'to': 4,\n",
       "             'trap': 4,\n",
       "             'it.': 2,\n",
       "             'And': 1,\n",
       "             'asks': 1,\n",
       "             'for': 1,\n",
       "             'help.': 2,\n",
       "             'will': 2,\n",
       "             'tell': 1,\n",
       "             'position': 1,\n",
       "             'he': 4,\n",
       "             'has': 3,\n",
       "             'To': 1,\n",
       "             'it,': 1,\n",
       "             'draw': 1,\n",
       "             'polygon': 5,\n",
       "             'with': 1,\n",
       "             'his': 1,\n",
       "             'buster': 1,\n",
       "             'sword,': 1,\n",
       "             'strictly': 1,\n",
       "             'inside': 1,\n",
       "             '(not': 1,\n",
       "             'border': 1,\n",
       "             'polygon)': 1,\n",
       "             'smallest': 1,\n",
       "             'possible': 1,\n",
       "             'perimeter.': 1,\n",
       "             'vertices': 1,\n",
       "             'must': 1,\n",
       "             'be': 1,\n",
       "             'white': 2,\n",
       "             'Even': 1,\n",
       "             'though': 1,\n",
       "             'super': 1,\n",
       "             'awesome,': 1,\n",
       "             'needs': 1,\n",
       "             'your': 1,\n",
       "             'Given': 1,\n",
       "             'positions': 1,\n",
       "             'star,': 1,\n",
       "             'you': 1,\n",
       "             'need': 1,\n",
       "             'find': 2,\n",
       "             'out': 1,\n",
       "             'whether': 1,\n",
       "             'can': 1,\n",
       "             'if': 1,\n",
       "             'can,': 1,\n",
       "             'also': 1,\n",
       "             'minimum': 1,\n",
       "             'length': 1,\n",
       "             'perimeter': 1,\n",
       "             'use.': 1})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bojRdd_base\\\n",
    ".flatMap(lambda x: x.split())\\\n",
    ".map(lambda x:(x,1))\\\n",
    ".countByKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
